{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy: 1.11.1\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.5\n",
      "anndata: 0.12.6\n",
      "celltypist: 1.7.1\n",
      "scipy: 1.16.3\n",
      "statsmodels: 0.14.5\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import glob\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import celltypist\n",
    "\n",
    "\n",
    "print(\"scanpy:\", sc.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"anndata:\", ad.__version__)\n",
    "print(\"celltypist:\", celltypist.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize containers for per-file pseudobulk matrices and metadata\n",
    "\n",
    "pb_results = []\n",
    "meta_results = []\n",
    "\n",
    "# Load a single CellTypist model \n",
    "\n",
    "model = celltypist.models.Model.load(\n",
    "\"ref_pbmc_clean_celltypist_model_AIFI_L3_2024-04-19.pkl\"\n",
    ")\n",
    "# Collect 10x .h5 files from the data directory\n",
    "h5_files = glob.glob(\"../data/*.h5\")\n",
    "\n",
    "# Process each file individually\n",
    "for f in h5_files:\n",
    "    # Derive sample ID from filename prefix before first underscore\n",
    "    sample_id = os.path.basename(f).split(\"_\")[0]\n",
    "    print(f\"Processing {sample_id}\")\n",
    "\n",
    "    # Read 10x Genomics HDF5 and add sample_id to cell metadata\n",
    "    adata = sc.read_10x_h5(f)\n",
    "    adata.var_names_make_unique()\n",
    "    adata.obs[\"sample_id\"] = sample_id\n",
    "\n",
    "    # Preserve raw counts before any normalization\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "\n",
    "    # Light gene filter: keep genes expressed in at least 20 cells\n",
    "    sc.pp.filter_genes(adata, min_cells=20)\n",
    "\n",
    "    # Normalize only for CellTypist\n",
    "    adata.X = adata.X.astype(\"float32\")\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    # Cell type annotation with CellTypist, majority voting for robustness\n",
    "    pred = celltypist.annotate(\n",
    "        adata,\n",
    "        model=model,\n",
    "        majority_voting=True\n",
    "    )\n",
    "    adata.obs[\"cell_type\"] = pred.predicted_labels[\"predicted_labels\"]\n",
    "\n",
    "    # Restore raw count matrix for pseudobulk aggregation\n",
    "    adata.X = adata.layers[\"counts\"]\n",
    "\n",
    "    # Per-file containers for pseudobulk vectors and metadata rows\n",
    "    pb = []\n",
    "    meta = []\n",
    "\n",
    "    # Aggregate counts per annotated cell type\n",
    "    for ct in adata.obs[\"cell_type\"].unique():\n",
    "        # Select cells of this cell type and count them\n",
    "        idx = (adata.obs[\"cell_type\"] == ct).to_numpy()\n",
    "        n_cells = idx.sum()\n",
    "\n",
    "        # Require at least 20 cells to form a pseudobulk\n",
    "        if n_cells < 20:\n",
    "            continue\n",
    "        \n",
    "        # Sum raw counts across cells for this cell type\n",
    "        counts = adata.X[idx].sum(axis=0)\n",
    "\n",
    "        # Store pseudobulk as a Series with gene names as index\n",
    "        pb.append(pd.Series(\n",
    "            np.asarray(counts).ravel(),\n",
    "            index=adata.var_names,\n",
    "            name=(sample_id, ct)\n",
    "        ))\n",
    "\n",
    "        # Store metadata for this pseudobulk\n",
    "        sub = adata.obs.loc[idx]\n",
    "        meta.append({\n",
    "        \"sample_id\": sample_id,\n",
    "        \"cell_type\": ct,\n",
    "        \"n_cells\": n_cells\n",
    "    })\n",
    "\n",
    "    # Convert list of Series to a DataFrame\n",
    "    pb = pd.DataFrame(pb)\n",
    "\n",
    "    # Set a MultiIndex for rows: (sample_id, cell_type)\n",
    "    pb.index = pd.MultiIndex.from_tuples(\n",
    "        pb.index,\n",
    "        names=[\"sample_id\", \"cell_type\"]\n",
    "    )\n",
    "\n",
    "    # Accumulate results across files\n",
    "    pb_results.append(pb)\n",
    "    meta_results.append(pd.DataFrame(meta))\n",
    "\n",
    "    # Delete the adata object to free up memory\n",
    "    del adata  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate per-file results into single DataFrames\n",
    "pb_all = pd.concat(pb_results, axis=0)\n",
    "meta_all = pd.concat(meta_results, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined pseudobulk counts and metadata to CSV\n",
    "pb_all.to_csv(\"pb_all.csv\")\n",
    "meta_all.to_csv(\"meta_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csvs\n",
    "meta_all = pd.read_csv(\"meta_all.csv\")\n",
    "pb_all = pd.read_csv(\"pb_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_type\n",
       "Core naive CD4 T cell    840143\n",
       "GZMK- CD56dim NK cell    552613\n",
       "IL1B+ CD14 monocyte      443051\n",
       "Core CD14 monocyte       303364\n",
       "Core naive B cell        279869\n",
       "                          ...  \n",
       "Memory CD8 Treg             678\n",
       "CLP cell                    344\n",
       "GZMK+ memory CD4 Treg       156\n",
       "ISG+ MAIT                   124\n",
       "BaEoMaP cell                 20\n",
       "Name: n_cells, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect metadata to find cell types with the largest numbers of cells per pseudobulk\n",
    "# Based on the sorted metadata, chose most abundant cell types to compare across samples\n",
    "cell_counts = meta_all.groupby('cell_type')['n_cells'].sum()\n",
    "\n",
    "cell_counts.sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
